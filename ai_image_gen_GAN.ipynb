{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Set up the NASA API endpoint and your API key\n",
        "api_key = 'UEqzMrdDTnNXcCmi1csUpL8dH1CY4QSSalfaimiM'\n",
        "url = f'https://images-api.nasa.gov/search?q=galaxy&media_type=image'\n",
        "\n",
        "# Make a request to the API\n",
        "response = requests.get(url)\n",
        "data = response.json()"
      ],
      "metadata": {
        "id": "1shiJ-oO2wWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29KP0TMXh-8B",
        "outputId": "468e0242-5629-490d-a9db-ff438d91f541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images downloaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Directory to save images\n",
        "save_dir = 'nasa_images'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Download images\n",
        "for item in data['collection']['items']:\n",
        "    image_url = item['links'][0]['href']\n",
        "    image_name = os.path.join(save_dir, image_url.split('/')[-1])\n",
        "    img_data = requests.get(image_url).content\n",
        "    with open(image_name, 'wb') as handler:\n",
        "        handler.write(img_data)\n",
        "\n",
        "print('Images downloaded successfully!')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Function to download images from NASA API based on a keyword\n",
        "def download_images(keyword, save_dir='nasa_images'):\n",
        "    url = f'https://images-api.nasa.gov/search?q={keyword}&media_type=image'\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    if 'collection' not in data or 'items' not in data['collection']:\n",
        "        print(f\"No images found for keyword: {keyword}\")\n",
        "        return\n",
        "\n",
        "    for item in data['collection']['items']:\n",
        "        if 'links' in item and len(item['links']) > 0:\n",
        "            image_url = item['links'][0]['href']\n",
        "            image_name = os.path.join(save_dir, image_url.split('/')[-1])\n",
        "            img_data = requests.get(image_url).content\n",
        "            with open(image_name, 'wb') as handler:\n",
        "                handler.write(img_data)\n",
        "\n",
        "    print(f'Images downloaded for keyword: {keyword}')\n",
        "\n",
        "# Directory to save images\n",
        "save_dir = 'nasa_images'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# List of keywords to search\n",
        "keywords = ['galaxy', 'nebula', 'planet', 'star', 'moon', 'astronomy']\n",
        "\n",
        "# Download images for each keyword\n",
        "for keyword in keywords:\n",
        "    download_images(keyword, save_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0SiLq_U4iX7",
        "outputId": "ebea62cc-e9b0-47cd-c0f7-f2442d733926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images downloaded for keyword: galaxy\n",
            "Images downloaded for keyword: nebula\n",
            "Images downloaded for keyword: planet\n",
            "Images downloaded for keyword: star\n",
            "Images downloaded for keyword: moon\n",
            "Images downloaded for keyword: astronomy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Function to download images from NASA API based on a keyword and save them in category folders\n",
        "def download_images(keyword, category, save_dir='nasa_images'):\n",
        "    url = f'https://images-api.nasa.gov/search?q={keyword}&media_type=image'\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    # Check if the collection contains items\n",
        "    if 'collection' not in data or 'items' not in data['collection']:\n",
        "        print(f\"No images found for keyword: {keyword}\")\n",
        "        return\n",
        "\n",
        "    # Create the category directory if it doesn't exist\n",
        "    category_dir = os.path.join(save_dir, category)\n",
        "    os.makedirs(category_dir, exist_ok=True)\n",
        "\n",
        "    for item in data['collection']['items']:\n",
        "        if 'links' in item and len(item['links']) > 0:\n",
        "            image_url = item['links'][0]['href']\n",
        "            image_name = os.path.join(category_dir, image_url.split('/')[-1])\n",
        "            img_data = requests.get(image_url).content\n",
        "            with open(image_name, 'wb') as handler:\n",
        "                handler.write(img_data)\n",
        "\n",
        "    print(f'Images downloaded for keyword: {keyword} in category: {category}')\n",
        "\n",
        "# Directory to save images\n",
        "save_dir = 'nasa_images'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Keywords and corresponding categories\n",
        "keywords = {\n",
        "    'galaxy': 'galaxies',\n",
        "    'nebula': 'nebulae',\n",
        "    'planet': 'planets',\n",
        "    'star': 'stars',\n",
        "    'moon': 'moon',\n",
        "    'cosmos': 'cosmos',\n",
        "    'constellation': 'constellations'\n",
        "}\n",
        "\n",
        "# Download images for each keyword and categorize them\n",
        "for keyword, category in keywords.items():\n",
        "    download_images(keyword, category, save_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsatUS3C8FgP",
        "outputId": "c10ac58c-55d2-4fdf-db5c-5213170fafee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images downloaded for keyword: galaxy in category: galaxies\n",
            "Images downloaded for keyword: nebula in category: nebulae\n",
            "Images downloaded for keyword: planet in category: planets\n",
            "Images downloaded for keyword: star in category: stars\n",
            "Images downloaded for keyword: moon in category: moon\n",
            "Images downloaded for keyword: cosmos in category: cosmos\n",
            "Images downloaded for keyword: constellation in category: constellations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('nasa_images', 'zip', 'nasa_images')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ExtqrQlI9W3I",
        "outputId": "ce4890de-64be-4311-8aa7-3b22a3035732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/nasa_images.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY-sao909dy1",
        "outputId": "f36b6a46-26b2-4e86-e371-350caaae39f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8.0  # Adjust the version as needed\n",
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXX_wehsCc2N",
        "outputId": "10abe4bf-6412-4640-8cf2-16d4f70e41e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.11.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.64.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.31.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
            "Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "lbPECCymIS1W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your dataset\n",
        "dataset_path = '/content/drive/My Drive/space images'"
      ],
      "metadata": {
        "id": "auclcuPmQhuu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='input',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='input',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1kKs05GCksC",
        "outputId": "d882ed9d-f961-430d-941c-27a8d26114a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2287 images belonging to 7 classes.\n",
            "Found 567 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "descriptions = [\"moon\", \"planets\", \"stars\", \"constellations\", \"cosmos\"]\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(descriptions)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "encoded_texts = tokenizer.texts_to_sequences(descriptions)\n",
        "max_length = max([len(s.split()) for s in descriptions])\n",
        "padded_texts = pad_sequences(encoded_texts, maxlen=max_length, padding='post')\n",
        "\n",
        "# Embedding layer\n",
        "embedding_dim = 100\n",
        "embedding_layer = Embedding(vocab_size, embedding_dim, input_length=max_length)"
      ],
      "metadata": {
        "id": "GOPVzDOx87P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(z,reuse=None):\n",
        "\n",
        "    with tf.variable_scope('generator',reuse=reuse):\n",
        "\n",
        "        hidden1 = tf.layers.dense(inputs=z,units=128,activation=tf.nn.leaky_relu)\n",
        "        hidden2 = tf.layers.dense(inputs=hidden1,units=128,activation=tf.nn.leaky_relu)\n",
        "        output = tf.layers.dense(inputs=hidden2,units=784,activation=tf.nn.tanh)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "8Mbcix-DUCkr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator(X,reuse=None):\n",
        "\n",
        "    with tf.variable_scope('discriminator',reuse=reuse):\n",
        "\n",
        "        hidden1 = tf.layers.dense(inputs=X,units=128,activation=tf.nn.leaky_relu)\n",
        "        hidden2 = tf.layers.dense(inputs=hidden1,units=128,activation=tf.nn.leaky_relu)\n",
        "        logits = tf.layers.dense(inputs=hidden2,units=1)\n",
        "        output = tf.sigmoid(logits)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "qBKYXcgIUFrW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator model\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256*4*4, input_dim=100))  # Start with a smaller feature map size\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((4, 4, 256)))  # Corresponding reshape\n",
        "\n",
        "    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))  # 8x8x128\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))  # 16x16x64\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(32, kernel_size=4, strides=2, padding='same'))  # 32x32x32\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(16, kernel_size=4, strides=2, padding='same'))  # 64x64x16\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(8, kernel_size=4, strides=2, padding='same'))  # 128x128x8\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh'))  # 256x256x3\n",
        "\n",
        "    return model\n",
        "\n",
        "# Discriminator model\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=4, strides=2, input_shape=(256, 256, 3), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Build and compile discriminator\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Build generator\n",
        "generator = build_generator()\n",
        "\n",
        "# Set discriminator as not trainable\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Create GAN model\n",
        "gan = Sequential([generator, discriminator])\n",
        "\n",
        "# Compile GAN\n",
        "gan.compile(optimizer='adam', loss='binary_crossentropy')\n"
      ],
      "metadata": {
        "id": "4_KhLwAWCnOS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "XLsUhlrgZN4s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate latent points\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    x_input = np.random.randn(latent_dim * n_samples)\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input\n",
        "\n",
        "# Generate fake samples\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    X = generator.predict(x_input)\n",
        "    y = np.zeros((n_samples, 1))\n",
        "    return X, y\n",
        "\n",
        "#Train the GAN\n",
        "def train_gan(gan, generator, discriminator, dataset, latent_dim, n_epochs=10000, n_batch=32):\n",
        "    half_batch = n_batch // 2\n",
        "\n",
        "    for i in range(n_epochs):\n",
        "        # Get a batch of real images\n",
        "        X_real, _ = dataset.next()\n",
        "\n",
        "        # If the batch size is not as expected, adjust it\n",
        "        if X_real.shape[0] < half_batch:\n",
        "            continue\n",
        "\n",
        "        y_real = np.ones((half_batch, 1))\n",
        "\n",
        "        # Generate a batch of fake images\n",
        "        X_fake, y_fake = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "\n",
        "        # Concatenate real and fake images\n",
        "        X, y = np.vstack((X_real[:half_batch], X_fake)), np.vstack((y_real, y_fake))\n",
        "\n",
        "        # Train the discriminator\n",
        "        d_loss, d_acc = discriminator.train_on_batch(X, y)\n",
        "\n",
        "        # Prepare points in latent space as input for the generator\n",
        "        X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "        y_gan = np.ones((n_batch, 1))\n",
        "\n",
        "        # Train the generator via the discriminator's error\n",
        "        g_loss = gan.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "        # Summarize loss on this batch\n",
        "        print(f'>{i+1}, d={d_loss:.3f}, g={g_loss:.3f}')\n",
        "\n",
        "        # Save the generator model every 1000 epochs\n",
        "        if (i + 1) % 1000 == 0:\n",
        "            generator.save(f'generator_model_{i+1}.h5')\n",
        "\n",
        "#Define the size of the latent space\n",
        "latent_dim = 100\n",
        "\n",
        "#Train the GAN\n",
        "train_gan(gan, generator, discriminator, train_generator, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9Fr6vp5454D",
        "outputId": "1fe70039-0c88-4933-da05-a01221fbc643"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">1, d=0.233, g=1.016\n",
            ">2, d=0.147, g=0.150\n",
            ">3, d=0.087, g=0.040\n",
            ">4, d=0.175, g=0.014\n",
            ">5, d=0.457, g=0.014\n",
            ">6, d=0.828, g=0.046\n",
            ">7, d=0.232, g=0.158\n",
            ">8, d=0.102, g=0.469\n",
            ">9, d=0.497, g=1.200\n",
            ">10, d=0.363, g=0.922\n",
            ">11, d=0.224, g=0.087\n",
            ">12, d=0.421, g=0.004\n",
            ">13, d=0.015, g=0.000\n",
            ">14, d=0.123, g=0.000\n",
            ">15, d=0.111, g=0.000\n",
            ">16, d=0.367, g=0.000\n",
            ">17, d=0.341, g=0.000\n",
            ">18, d=0.229, g=0.000\n",
            ">19, d=0.006, g=0.000\n",
            ">20, d=0.008, g=0.000\n",
            ">21, d=0.000, g=0.000\n",
            ">23, d=0.002, g=0.000\n",
            ">24, d=0.004, g=0.000\n",
            ">25, d=0.003, g=0.000\n",
            ">26, d=0.008, g=0.001\n",
            ">27, d=0.006, g=0.004\n",
            ">28, d=0.073, g=0.000\n",
            ">29, d=0.011, g=0.000\n",
            ">30, d=0.022, g=0.000\n",
            ">31, d=0.006, g=0.000\n",
            ">32, d=0.021, g=0.001\n",
            ">33, d=0.037, g=0.000\n",
            ">34, d=0.006, g=0.000\n",
            ">35, d=0.003, g=0.000\n",
            ">36, d=0.001, g=0.000\n",
            ">37, d=0.001, g=0.000\n",
            ">38, d=0.003, g=0.000\n",
            ">39, d=0.000, g=0.000\n",
            ">40, d=0.000, g=0.000\n",
            ">41, d=0.001, g=0.000\n",
            ">42, d=0.000, g=0.000\n",
            ">43, d=0.001, g=0.000\n",
            ">44, d=0.000, g=0.000\n",
            ">45, d=0.000, g=0.000\n",
            ">46, d=0.000, g=0.000\n",
            ">47, d=0.000, g=0.000\n",
            ">48, d=0.002, g=0.000\n",
            ">49, d=0.001, g=0.000\n",
            ">50, d=0.005, g=0.000\n",
            ">51, d=0.000, g=0.000\n",
            ">52, d=0.002, g=0.000\n",
            ">53, d=0.024, g=0.000\n",
            ">54, d=0.000, g=0.000\n",
            ">55, d=0.002, g=0.000\n",
            ">56, d=0.000, g=0.000\n",
            ">57, d=0.001, g=0.000\n",
            ">58, d=0.006, g=0.000\n",
            ">59, d=0.002, g=0.000\n",
            ">60, d=0.000, g=0.000\n",
            ">61, d=0.000, g=0.000\n",
            ">62, d=0.002, g=0.000\n",
            ">63, d=0.001, g=0.000\n",
            ">64, d=0.014, g=0.000\n",
            ">65, d=0.001, g=0.000\n",
            ">66, d=0.001, g=0.000\n",
            ">67, d=0.011, g=0.000\n",
            ">68, d=0.000, g=0.000\n",
            ">69, d=0.000, g=0.000\n",
            ">70, d=0.000, g=0.000\n",
            ">71, d=0.006, g=0.000\n",
            ">72, d=0.001, g=0.000\n",
            ">73, d=0.005, g=0.000\n",
            ">74, d=0.000, g=0.000\n",
            ">75, d=0.005, g=0.000\n",
            ">76, d=0.046, g=0.000\n",
            ">77, d=0.000, g=0.000\n",
            ">78, d=0.160, g=0.000\n",
            ">79, d=0.000, g=0.000\n",
            ">80, d=0.000, g=0.000\n",
            ">81, d=0.000, g=0.000\n",
            ">82, d=0.000, g=0.000\n",
            ">83, d=0.008, g=0.000\n",
            ">84, d=0.000, g=0.000\n",
            ">85, d=0.000, g=0.000\n",
            ">86, d=0.000, g=0.000\n",
            ">87, d=0.000, g=0.000\n",
            ">88, d=0.000, g=0.000\n",
            ">89, d=0.000, g=0.000\n",
            ">90, d=0.005, g=0.000\n",
            ">91, d=0.000, g=0.000\n",
            ">92, d=0.000, g=0.000\n",
            ">93, d=0.001, g=0.000\n",
            ">95, d=0.000, g=0.000\n",
            ">96, d=0.001, g=0.000\n",
            ">97, d=0.000, g=0.000\n",
            ">98, d=0.001, g=0.000\n",
            ">99, d=0.006, g=0.000\n",
            ">100, d=0.000, g=0.000\n",
            ">101, d=0.000, g=0.000\n",
            ">102, d=0.000, g=0.000\n",
            ">103, d=0.001, g=0.000\n",
            ">104, d=0.000, g=0.000\n",
            ">105, d=0.000, g=0.000\n",
            ">106, d=0.001, g=0.000\n",
            ">107, d=0.000, g=0.000\n",
            ">108, d=0.000, g=0.000\n",
            ">109, d=0.001, g=0.000\n",
            ">110, d=0.000, g=0.000\n",
            ">111, d=0.000, g=0.000\n",
            ">112, d=0.000, g=0.000\n",
            ">113, d=0.000, g=0.000\n",
            ">114, d=0.001, g=0.000\n",
            ">115, d=0.000, g=0.000\n",
            ">116, d=0.001, g=0.000\n",
            ">117, d=0.000, g=0.000\n",
            ">118, d=0.000, g=0.000\n",
            ">119, d=0.001, g=0.000\n",
            ">120, d=0.076, g=0.000\n",
            ">121, d=0.000, g=0.000\n",
            ">122, d=0.000, g=0.000\n",
            ">123, d=0.000, g=0.000\n",
            ">124, d=0.001, g=0.000\n",
            ">125, d=0.001, g=0.000\n",
            ">126, d=0.000, g=0.000\n",
            ">127, d=0.000, g=0.000\n",
            ">128, d=0.000, g=0.000\n",
            ">129, d=0.000, g=0.000\n",
            ">130, d=0.001, g=0.000\n",
            ">131, d=0.003, g=0.000\n",
            ">132, d=0.002, g=0.000\n",
            ">133, d=0.000, g=0.000\n",
            ">134, d=0.000, g=0.000\n",
            ">135, d=0.035, g=0.000\n",
            ">136, d=0.003, g=0.000\n",
            ">137, d=0.000, g=0.000\n",
            ">138, d=0.009, g=0.000\n",
            ">139, d=0.000, g=0.000\n",
            ">140, d=0.000, g=0.000\n",
            ">141, d=0.000, g=0.000\n",
            ">142, d=0.000, g=0.000\n",
            ">143, d=0.000, g=0.000\n",
            ">144, d=0.022, g=0.000\n",
            ">145, d=0.126, g=0.000\n",
            ">146, d=0.148, g=0.000\n",
            ">147, d=0.001, g=0.000\n",
            ">148, d=0.004, g=0.000\n",
            ">149, d=0.000, g=0.000\n",
            ">150, d=0.002, g=0.000\n",
            ">151, d=0.002, g=0.000\n",
            ">152, d=0.000, g=0.000\n",
            ">153, d=0.023, g=0.000\n",
            ">154, d=0.003, g=0.000\n",
            ">155, d=0.000, g=0.000\n",
            ">156, d=0.000, g=0.000\n",
            ">157, d=0.002, g=0.000\n",
            ">158, d=0.001, g=0.000\n",
            ">159, d=0.000, g=0.000\n",
            ">160, d=0.000, g=0.000\n",
            ">161, d=0.003, g=0.000\n",
            ">162, d=0.002, g=0.001\n",
            ">163, d=0.000, g=0.000\n",
            ">164, d=0.002, g=0.000\n",
            ">165, d=0.000, g=0.000\n",
            ">167, d=0.000, g=0.000\n",
            ">168, d=0.003, g=0.000\n",
            ">169, d=0.000, g=0.000\n",
            ">170, d=0.000, g=0.000\n",
            ">171, d=0.000, g=0.000\n",
            ">172, d=0.001, g=0.000\n",
            ">173, d=0.000, g=0.000\n",
            ">174, d=0.000, g=0.000\n",
            ">175, d=0.001, g=0.000\n",
            ">176, d=0.000, g=0.000\n",
            ">177, d=0.001, g=0.000\n",
            ">178, d=0.002, g=0.000\n",
            ">179, d=0.000, g=0.000\n",
            ">180, d=0.001, g=0.000\n",
            ">181, d=0.000, g=0.000\n",
            ">182, d=0.000, g=0.000\n",
            ">183, d=0.040, g=0.000\n",
            ">184, d=0.000, g=0.000\n",
            ">185, d=0.000, g=0.000\n",
            ">186, d=0.000, g=0.000\n",
            ">187, d=0.001, g=0.000\n",
            ">188, d=0.000, g=0.000\n",
            ">189, d=0.001, g=0.000\n",
            ">190, d=0.000, g=0.000\n",
            ">191, d=0.000, g=0.000\n",
            ">192, d=0.000, g=0.000\n",
            ">193, d=0.008, g=0.000\n",
            ">194, d=0.002, g=0.000\n",
            ">195, d=0.000, g=0.000\n",
            ">196, d=0.000, g=0.000\n",
            ">197, d=0.001, g=0.000\n",
            ">198, d=0.000, g=0.000\n",
            ">199, d=0.001, g=0.000\n",
            ">200, d=0.000, g=0.000\n",
            ">201, d=0.000, g=0.000\n",
            ">202, d=0.000, g=0.000\n",
            ">203, d=0.000, g=0.000\n",
            ">204, d=0.000, g=0.000\n",
            ">205, d=0.000, g=0.000\n",
            ">206, d=0.000, g=0.000\n",
            ">207, d=0.000, g=0.000\n",
            ">208, d=0.001, g=0.000\n",
            ">209, d=0.000, g=0.000\n",
            ">210, d=0.000, g=0.000\n",
            ">211, d=0.000, g=0.000\n",
            ">212, d=0.000, g=0.000\n",
            ">213, d=0.004, g=0.000\n",
            ">214, d=0.001, g=0.000\n",
            ">215, d=0.001, g=0.000\n",
            ">216, d=0.000, g=0.000\n",
            ">217, d=0.003, g=0.000\n",
            ">218, d=0.001, g=0.000\n",
            ">219, d=0.000, g=0.000\n",
            ">220, d=0.000, g=0.000\n",
            ">221, d=0.000, g=0.000\n",
            ">222, d=0.000, g=0.000\n",
            ">223, d=0.000, g=0.000\n",
            ">224, d=0.000, g=0.000\n",
            ">225, d=0.000, g=0.000\n",
            ">226, d=0.000, g=0.000\n",
            ">227, d=0.001, g=0.000\n",
            ">228, d=0.000, g=0.000\n",
            ">229, d=0.024, g=0.000\n",
            ">230, d=0.000, g=0.000\n",
            ">231, d=0.002, g=0.000\n",
            ">232, d=0.001, g=0.000\n",
            ">233, d=0.000, g=0.000\n",
            ">234, d=0.000, g=0.000\n",
            ">235, d=0.000, g=0.001\n",
            ">236, d=0.000, g=0.000\n",
            ">237, d=0.001, g=0.000\n",
            ">239, d=0.001, g=0.000\n",
            ">240, d=0.000, g=0.001\n",
            ">241, d=0.003, g=0.000\n",
            ">242, d=0.001, g=0.000\n",
            ">243, d=0.001, g=0.000\n",
            ">244, d=0.001, g=0.000\n",
            ">245, d=0.008, g=0.000\n",
            ">246, d=0.000, g=0.000\n",
            ">247, d=0.006, g=0.000\n",
            ">248, d=0.000, g=0.000\n",
            ">249, d=0.000, g=0.000\n",
            ">250, d=0.000, g=0.000\n",
            ">251, d=0.001, g=0.000\n",
            ">252, d=0.000, g=0.000\n",
            ">253, d=0.001, g=0.000\n",
            ">254, d=0.001, g=0.000\n",
            ">255, d=0.000, g=0.000\n",
            ">256, d=0.000, g=0.000\n",
            ">257, d=0.000, g=0.000\n",
            ">258, d=0.004, g=0.000\n",
            ">259, d=0.000, g=0.000\n",
            ">260, d=0.000, g=0.000\n",
            ">261, d=0.000, g=0.000\n",
            ">262, d=0.000, g=0.000\n",
            ">263, d=0.000, g=0.000\n",
            ">264, d=0.000, g=0.000\n",
            ">265, d=0.001, g=0.000\n",
            ">266, d=0.001, g=0.000\n",
            ">267, d=0.005, g=0.000\n",
            ">268, d=0.002, g=0.000\n",
            ">269, d=0.000, g=0.000\n",
            ">270, d=0.000, g=0.000\n",
            ">271, d=0.004, g=0.000\n",
            ">272, d=0.002, g=0.000\n",
            ">273, d=0.001, g=0.000\n",
            ">274, d=0.000, g=0.000\n",
            ">275, d=0.002, g=0.000\n",
            ">276, d=0.001, g=0.000\n",
            ">277, d=0.001, g=0.000\n",
            ">278, d=0.000, g=0.000\n",
            ">279, d=0.000, g=0.000\n",
            ">280, d=0.001, g=0.000\n",
            ">281, d=0.001, g=0.000\n",
            ">282, d=0.001, g=0.000\n",
            ">283, d=0.000, g=0.000\n",
            ">284, d=0.024, g=0.000\n",
            ">285, d=0.000, g=0.000\n",
            ">286, d=0.000, g=0.000\n",
            ">287, d=0.000, g=0.000\n",
            ">288, d=0.000, g=0.000\n",
            ">289, d=0.000, g=0.000\n",
            ">290, d=0.001, g=0.000\n",
            ">291, d=0.000, g=0.000\n",
            ">292, d=0.000, g=0.000\n",
            ">293, d=0.000, g=0.000\n",
            ">294, d=0.000, g=0.000\n",
            ">295, d=0.000, g=0.000\n",
            ">296, d=0.001, g=0.000\n",
            ">297, d=0.002, g=0.000\n",
            ">298, d=0.009, g=0.000\n",
            ">299, d=0.000, g=0.000\n",
            ">300, d=0.001, g=0.000\n",
            ">301, d=0.007, g=0.000\n",
            ">302, d=0.000, g=0.000\n",
            ">303, d=0.001, g=0.000\n",
            ">304, d=0.000, g=0.000\n",
            ">305, d=0.000, g=0.000\n",
            ">306, d=0.000, g=0.000\n",
            ">307, d=0.000, g=0.000\n",
            ">308, d=0.000, g=0.000\n",
            ">309, d=0.000, g=0.000\n",
            ">311, d=0.000, g=0.000\n",
            ">312, d=0.000, g=0.000\n",
            ">313, d=0.000, g=0.000\n",
            ">314, d=0.000, g=0.000\n",
            ">315, d=0.000, g=0.000\n",
            ">316, d=0.000, g=0.000\n",
            ">317, d=0.000, g=0.000\n",
            ">318, d=0.000, g=0.000\n",
            ">319, d=0.000, g=0.000\n",
            ">320, d=0.000, g=0.000\n",
            ">321, d=0.000, g=0.000\n",
            ">322, d=0.000, g=0.000\n",
            ">323, d=0.003, g=0.000\n",
            ">324, d=0.001, g=0.000\n",
            ">325, d=0.002, g=0.000\n",
            ">326, d=0.000, g=0.000\n",
            ">327, d=0.001, g=0.000\n",
            ">328, d=0.000, g=0.000\n",
            ">329, d=0.000, g=0.000\n",
            ">330, d=0.000, g=0.000\n",
            ">331, d=0.000, g=0.000\n",
            ">332, d=0.000, g=0.000\n",
            ">333, d=0.001, g=0.000\n",
            ">334, d=0.000, g=0.000\n",
            ">335, d=0.001, g=0.000\n",
            ">336, d=0.000, g=0.000\n",
            ">337, d=0.001, g=0.000\n",
            ">338, d=0.000, g=0.000\n",
            ">339, d=0.000, g=0.000\n",
            ">340, d=0.002, g=0.000\n",
            ">341, d=0.002, g=0.000\n",
            ">342, d=0.001, g=0.000\n",
            ">343, d=0.000, g=0.000\n",
            ">344, d=0.000, g=0.000\n",
            ">345, d=0.000, g=0.000\n",
            ">346, d=0.000, g=0.000\n",
            ">347, d=0.002, g=0.000\n",
            ">348, d=0.000, g=0.000\n",
            ">349, d=0.000, g=0.000\n",
            ">350, d=0.000, g=0.000\n",
            ">351, d=0.005, g=0.000\n",
            ">352, d=0.000, g=0.000\n",
            ">353, d=0.000, g=0.000\n",
            ">354, d=0.001, g=0.000\n",
            ">355, d=0.000, g=0.000\n",
            ">356, d=0.000, g=0.000\n",
            ">357, d=0.000, g=0.000\n",
            ">358, d=0.000, g=0.000\n",
            ">359, d=0.000, g=0.000\n",
            ">360, d=0.000, g=0.000\n",
            ">361, d=0.000, g=0.000\n",
            ">362, d=0.000, g=0.000\n",
            ">363, d=0.000, g=0.000\n",
            ">364, d=0.001, g=0.000\n",
            ">365, d=0.000, g=0.000\n",
            ">366, d=0.155, g=0.000\n",
            ">367, d=0.007, g=0.000\n",
            ">368, d=0.000, g=0.000\n",
            ">369, d=0.000, g=0.000\n",
            ">370, d=0.000, g=0.000\n",
            ">371, d=0.001, g=0.000\n",
            ">372, d=0.001, g=0.000\n",
            ">373, d=0.000, g=0.000\n",
            ">374, d=0.014, g=0.000\n",
            ">375, d=0.000, g=0.000\n",
            ">376, d=0.002, g=0.000\n",
            ">377, d=0.003, g=0.000\n",
            ">378, d=0.001, g=0.000\n",
            ">379, d=0.000, g=0.000\n",
            ">380, d=0.002, g=0.000\n",
            ">381, d=0.000, g=0.000\n",
            ">383, d=0.000, g=0.000\n",
            ">384, d=0.004, g=0.000\n",
            ">385, d=0.022, g=0.000\n",
            ">386, d=0.000, g=0.000\n",
            ">387, d=0.003, g=0.000\n",
            ">388, d=0.045, g=0.000\n",
            ">389, d=0.000, g=0.000\n",
            ">390, d=0.000, g=0.000\n",
            ">391, d=0.000, g=0.000\n",
            ">392, d=0.000, g=0.000\n",
            ">393, d=0.000, g=0.000\n",
            ">394, d=0.002, g=0.000\n",
            ">395, d=0.005, g=0.000\n",
            ">396, d=0.000, g=0.000\n",
            ">397, d=0.004, g=0.000\n",
            ">398, d=0.002, g=0.000\n",
            ">399, d=0.001, g=0.000\n",
            ">400, d=0.000, g=0.000\n",
            ">401, d=0.004, g=0.000\n",
            ">402, d=0.001, g=0.000\n",
            ">403, d=0.011, g=0.000\n",
            ">404, d=0.003, g=0.000\n",
            ">405, d=0.001, g=0.000\n",
            ">406, d=0.001, g=0.000\n",
            ">407, d=0.014, g=0.000\n",
            ">408, d=0.001, g=0.000\n",
            ">409, d=0.001, g=0.000\n",
            ">410, d=0.002, g=0.000\n",
            ">411, d=0.000, g=0.000\n",
            ">412, d=0.000, g=0.000\n",
            ">413, d=0.000, g=0.000\n",
            ">414, d=0.001, g=0.000\n",
            ">415, d=0.000, g=0.000\n",
            ">416, d=0.000, g=0.000\n",
            ">417, d=0.000, g=0.000\n",
            ">418, d=0.002, g=0.000\n",
            ">419, d=0.000, g=0.000\n",
            ">420, d=0.000, g=0.000\n",
            ">421, d=0.001, g=0.000\n",
            ">422, d=0.000, g=0.000\n",
            ">423, d=0.000, g=0.000\n",
            ">424, d=0.000, g=0.000\n",
            ">425, d=0.001, g=0.000\n",
            ">426, d=0.000, g=0.000\n",
            ">427, d=0.000, g=0.000\n",
            ">428, d=0.000, g=0.000\n",
            ">429, d=0.000, g=0.000\n",
            ">430, d=0.000, g=0.000\n",
            ">431, d=0.000, g=0.000\n",
            ">432, d=0.000, g=0.000\n",
            ">433, d=0.000, g=0.000\n",
            ">434, d=0.000, g=0.000\n",
            ">435, d=0.001, g=0.000\n",
            ">436, d=0.000, g=0.000\n",
            ">437, d=0.000, g=0.000\n",
            ">438, d=0.000, g=0.000\n",
            ">439, d=0.000, g=0.000\n",
            ">440, d=0.000, g=0.000\n",
            ">441, d=0.000, g=0.000\n",
            ">442, d=0.000, g=0.000\n",
            ">443, d=0.000, g=0.000\n",
            ">444, d=0.004, g=0.000\n",
            ">445, d=0.001, g=0.000\n",
            ">446, d=0.000, g=0.000\n",
            ">447, d=0.000, g=0.000\n",
            ">448, d=0.000, g=0.000\n",
            ">449, d=0.000, g=0.000\n",
            ">450, d=0.000, g=0.000\n",
            ">451, d=0.000, g=0.000\n",
            ">452, d=0.000, g=0.000\n",
            ">453, d=0.000, g=0.000\n",
            ">455, d=0.000, g=0.000\n",
            ">456, d=0.000, g=0.000\n",
            ">457, d=0.000, g=0.000\n",
            ">458, d=0.001, g=0.000\n",
            ">459, d=0.000, g=0.000\n",
            ">460, d=0.002, g=0.000\n",
            ">461, d=0.000, g=0.000\n",
            ">462, d=0.000, g=0.000\n",
            ">463, d=0.000, g=0.000\n",
            ">464, d=0.000, g=0.000\n",
            ">465, d=0.000, g=0.000\n",
            ">466, d=0.000, g=0.000\n",
            ">467, d=0.000, g=0.000\n",
            ">468, d=0.000, g=0.000\n",
            ">469, d=0.000, g=0.000\n",
            ">470, d=0.000, g=0.000\n",
            ">471, d=0.000, g=0.000\n",
            ">472, d=0.000, g=0.000\n",
            ">473, d=0.000, g=0.000\n",
            ">474, d=0.001, g=0.000\n",
            ">475, d=0.000, g=0.000\n",
            ">476, d=0.000, g=0.000\n",
            ">477, d=0.000, g=0.000\n",
            ">478, d=0.000, g=0.000\n",
            ">479, d=0.000, g=0.000\n",
            ">480, d=0.000, g=0.000\n",
            ">481, d=0.000, g=0.000\n",
            ">482, d=0.001, g=0.000\n",
            ">483, d=0.000, g=0.000\n",
            ">484, d=0.000, g=0.000\n",
            ">485, d=0.000, g=0.000\n",
            ">486, d=0.000, g=0.000\n",
            ">487, d=0.000, g=0.000\n",
            ">488, d=0.009, g=0.000\n",
            ">489, d=0.000, g=0.000\n",
            ">490, d=0.000, g=0.000\n",
            ">491, d=0.002, g=0.000\n",
            ">492, d=0.000, g=0.000\n",
            ">493, d=0.000, g=0.000\n",
            ">494, d=0.000, g=0.000\n",
            ">495, d=0.000, g=0.000\n",
            ">496, d=0.000, g=0.000\n",
            ">497, d=0.000, g=0.000\n",
            ">498, d=0.000, g=0.000\n",
            ">499, d=0.000, g=0.000\n",
            ">500, d=0.001, g=0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the generator model\n",
        "generator = load_model('generator_model_10000.h5')\n",
        "\n",
        "# Generate new images\n",
        "latent_points = generate_latent_points(latent_dim, 1)\n",
        "generated_images = generator.predict(latent_points)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow((generated_images[0] + 1) / 2)  # Rescale from [-1, 1] to [0, 1]\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vm9B0nN1Xobu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}